{
    "log_path": "/home/stefan/SteamScrapers/CS2Scraper/logs/itemspider/steamspider/2025-06-23T19_58_14.log",
    "json_path": "/home/stefan/SteamScrapers/CS2Scraper/logs/itemspider/steamspider/2025-06-23T19_58_14.json",
    "json_url": "http://127.0.0.1:6800/logs/itemspider/steamspider/2025-06-23T19_58_14.json",
    "size": 11843,
    "position": 11843,
    "status": "ok",
    "_head": 100,
    "head": "2025-06-23 19:58:26 [scrapy.utils.log] INFO: Scrapy 2.13.2 started (bot: itemspider)\n2025-06-23 19:58:26 [scrapy.utils.log] INFO: Versions:\n{'lxml': '5.4.0',\n 'libxml2': '2.13.8',\n 'cssselect': '1.3.0',\n 'parsel': '1.10.0',\n 'w3lib': '2.0.0',\n 'Twisted': '25.5.0',\n 'Python': '3.13.3 (main, Apr  9 2025, 07:44:25) [GCC 14.2.1 20250207]',\n 'pyOpenSSL': '25.1.0 (OpenSSL 3.5.0 8 Apr 2025)',\n 'cryptography': '45.0.4',\n 'Platform': 'Linux-6.14.6-2-MANJARO-x86_64-with-glibc2.41'}\n2025-06-23 19:58:26 [scrapy.addons] INFO: Enabled addons:\n[]\n2025-06-23 19:58:26 [asyncio] DEBUG: Using selector: EpollSelector\n2025-06-23 19:58:26 [scrapy.utils.log] DEBUG: Using reactor: twisted.internet.asyncioreactor.AsyncioSelectorReactor\n2025-06-23 19:58:26 [scrapy.utils.log] DEBUG: Using asyncio event loop: asyncio.unix_events._UnixSelectorEventLoop\n2025-06-23 19:58:26 [scrapy.extensions.telnet] INFO: Telnet Password: 8b97e889124eb4e5\n2025-06-23 19:58:26 [scrapy.middleware] INFO: Enabled extensions:\n['scrapy.extensions.corestats.CoreStats',\n 'scrapy.extensions.telnet.TelnetConsole',\n 'scrapy.extensions.memusage.MemoryUsage',\n 'scrapy.extensions.logstats.LogStats',\n 'scrapy.extensions.throttle.AutoThrottle']\n2025-06-23 19:58:26 [scrapy.crawler] INFO: Overridden settings:\n{'AUTOTHROTTLE_ENABLED': True,\n 'AUTOTHROTTLE_START_DELAY': 10,\n 'AUTOTHROTTLE_TARGET_CONCURRENCY': 0.5,\n 'BOT_NAME': 'itemspider',\n 'CONCURRENT_REQUESTS': 1,\n 'DOWNLOAD_DELAY': 10,\n 'EDITOR': '/usr/bin/nano',\n 'FEED_EXPORT_ENCODING': 'utf-8',\n 'HTTPCACHE_IGNORE_HTTP_CODES': [429],\n 'LOG_FILE': '/home/stefan/SteamScrapers/CS2Scraper/logs/itemspider/steamspider/2025-06-23T19_58_14.log',\n 'NEWSPIDER_MODULE': 'itemspider.spiders',\n 'SPIDER_MODULES': ['itemspider.spiders']}\n2025-06-23 19:58:26 [scrapy.middleware] INFO: Enabled downloader middlewares:\n['scrapy.downloadermiddlewares.offsite.OffsiteMiddleware',\n 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',\n 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',\n 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',\n 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',\n 'itemspider.middlewares.ItemspiderDownloaderMiddleware',\n 'scrapy.downloadermiddlewares.retry.RetryMiddleware',\n 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',\n 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',\n 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',\n 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',\n 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',\n 'scrapy.downloadermiddlewares.stats.DownloaderStats']\n2025-06-23 19:58:26 [scrapy.middleware] INFO: Enabled spider middlewares:\n['scrapy.spidermiddlewares.start.StartSpiderMiddleware',\n 'scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',\n 'itemspider.middlewares.ItemspiderSpiderMiddleware',\n 'scrapy.spidermiddlewares.referer.RefererMiddleware',\n 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',\n 'scrapy.spidermiddlewares.depth.DepthMiddleware']\n2025-06-23 19:58:26 [py.warnings] WARNING: /home/stefan/SteamScrapers/CS2Scraper/.venv/lib/python3.13/site-packages/scrapy/core/spidermw.py:98: ScrapyDeprecationWarning: The following enabled spider middlewares, directly or through their parent classes, define the deprecated process_start_requests() method: itemspider.middlewares.ItemspiderSpiderMiddleware. process_start_requests() has been deprecated in favor of a new method, process_start(), to support asynchronous code execution. process_start_requests() will stop being called in a future version of Scrapy. If you use Scrapy 2.13 or higher only, replace process_start_requests() with process_start(); note that process_start() is a coroutine (async def). If you need to maintain compatibility with lower Scrapy versions, when defining process_start_requests() in a spider middleware class, define process_start() as well. See the release notes of Scrapy 2.13 for details: https://docs.scrapy.org/en/2.13/news.html\n  warn(\n\n2025-06-23 19:58:26 [scrapy.core.spidermw] WARNING: Middleware itemspider.middlewares.ItemspiderSpiderMiddleware doesn't support asynchronous spider output, this is deprecated and will stop working in a future version of Scrapy. The middleware should be updated to support it. Please see https://docs.scrapy.org/en/latest/topics/coroutines.html#for-middleware-users for more information.\n2025-06-23 19:58:26 [scrapy.middleware] INFO: Enabled item pipelines:\n['itemspider.pipelines.ItemspiderPipeline']\n2025-06-23 19:58:26 [scrapy.core.engine] INFO: Spider opened\n2025-06-23 19:58:26 [py.warnings] WARNING: /home/stefan/SteamScrapers/CS2Scraper/.venv/lib/python3.13/site-packages/scrapy/core/spidermw.py:433: ScrapyDeprecationWarning: itemspider.spiders.steamspider.SteamspiderSpider defines the deprecated start_requests() method. start_requests() has been deprecated in favor of a new method, start(), to support asynchronous code execution. start_requests() will stop being called in a future version of Scrapy. If you use Scrapy 2.13 or higher only, replace start_requests() with start(); note that start() is a coroutine (async def). If you need to maintain compatibility with lower Scrapy versions, when overriding start_requests() in a spider class, override start() as well; you can use super() to reuse the inherited start() implementation without copy-pasting. See the release notes of Scrapy 2.13 for details: https://docs.scrapy.org/en/2.13/news.html\n  warn(\n\n2025-06-23 19:58:26 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)\n2025-06-23 19:58:26 [steamspider] INFO: Spider opened: steamspider\n2025-06-23 19:58:26 [steamspider] INFO: Spider opened: steamspider\n2025-06-23 19:58:26 [scrapy.extensions.telnet] INFO: Telnet console listening on 127.0.0.1:6023\n2025-06-23 19:58:30 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://steamcommunity.com/market/search/render/?query=&start=4000&count=100&search_descriptions=0&sort_column=price&sort_dir=desc&appid=730> (referer: None)\n2025-06-23 19:58:38 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://steamcommunity.com/market/search/render/?query=&start=5000&count=100&search_descriptions=0&sort_column=price&sort_dir=desc&appid=730> (referer: https://steamcommunity.com/market/search/render/?query=&start=4000&count=100&search_descriptions=0&sort_column=price&sort_dir=desc&appid=730)\n2025-06-23 19:58:38 [scrapy.dupefilters] DEBUG: Filtered duplicate request: <GET https://steamcommunity.com/market/search/render/?query=&start=5000&count=100&search_descriptions=0&sort_column=price&sort_dir=desc&appid=730> - no more duplicates will be shown (see DUPEFILTER_DEBUG to show all duplicates)\n2025-06-23 19:58:55 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://steamcommunity.com/market/search/render/?query=&start=6900&count=100&search_descriptions=0&sort_column=price&sort_dir=desc&appid=730> (referer: https://steamcommunity.com/market/search/render/?query=&start=4000&count=100&search_descriptions=0&sort_column=price&sort_dir=desc&appid=730)\n2025-06-23 19:59:05 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://steamcommunity.com/market/listings/730/Dust%20II%20Pin> (referer: https://steamcommunity.com/market/search/render/?query=&start=5000&count=100&search_descriptions=0&sort_column=price&sort_dir=desc&appid=730)\n2025-06-23 19:59:05 [scrapy.core.scraper] DEBUG: Scraped from <200 https://steamcommunity.com/market/listings/730/Dust%20II%20Pin>\n{'buying_price': 48.64,\n 'profit': -1.12,\n 'selling_price': 47.39,\n 'url': 'https://steamcommunity.com/market/listings/730/Dust%20II%20Pin'}\n2025-06-23 19:59:19 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://steamcommunity.com/market/listings/730/AK-47%20%7C%20Head%20Shot%20%28Minimal%20Wear%29> (referer: https://steamcommunity.com/market/search/render/?query=&start=6900&count=100&search_descriptions=0&sort_column=price&sort_dir=desc&appid=730)\n2025-06-23 19:59:19 [scrapy.core.scraper] DEBUG: Scraped from <200 https://steamcommunity.com/market/listings/730/AK-47%20%7C%20Head%20Shot%20%28Minimal%20Wear%29>\n{'buying_price': 19.5,\n 'profit': -0.05,\n 'selling_price': 19.444,\n 'url': 'https://steamcommunity.com/market/listings/730/AK-47%20%7C%20Head%20Shot%20%28Minimal%20Wear%29'}\n2025-06-23 19:59:26 [scrapy.extensions.logstats] INFO: Crawled 5 pages (at 5 pages/min), scraped 2 items (at 2 items/min)\n2025-06-23 19:59:31 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://steamcommunity.com/market/listings/730/Sticker%20%7C%20GuardiaN%20%28Gold%29%20%7C%20Berlin%202019> (referer: https://steamcommunity.com/market/search/render/?query=&start=6900&count=100&search_descriptions=0&sort_column=price&sort_dir=desc&appid=730)\n2025-06-23 19:59:31 [scrapy.core.scraper] DEBUG: Scraped from <200 https://steamcommunity.com/market/listings/730/Sticker%20%7C%20GuardiaN%20%28Gold%29%20%7C%20Berlin%202019>\n{'buying_price': 19.5,\n 'profit': 0.99,\n 'selling_price': 20.597,\n 'url': 'https://steamcommunity.com/market/listings/730/Sticker%20%7C%20GuardiaN%20%28Gold%29%20%7C%20Berlin%202019'}\n2025-06-23 19:59:45 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://steamcommunity.com/market/listings/730/Sticker%20%7C%20Starry%20%28Gold%29%20%7C%20Copenhagen%202024> (referer: https://steamcommunity.com/market/search/render/?query=&start=6900&count=100&search_descriptions=0&sort_column=price&sort_dir=desc&appid=730)\n2025-06-23 19:59:45 [scrapy.core.scraper] DEBUG: Scraped from <200 https://steamcommunity.com/market/listings/730/Sticker%20%7C%20Starry%20%28Gold%29%20%7C%20Copenhagen%202024>\n{'buying_price': 19.5,\n 'profit': 0.56,\n 'selling_price': 20.12,\n 'url': 'https://steamcommunity.com/market/listings/730/Sticker%20%7C%20Starry%20%28Gold%29%20%7C%20Copenhagen%202024'}\n2025-06-23 19:59:54 [scrapy.crawler] INFO: Received SIGINT, shutting down gracefully. Send again to force ",
    "tail": "2025-06-23 19:58:26 [scrapy.utils.log] INFO: Scrapy 2.13.2 started (bot: itemspider)\n2025-06-23 19:58:26 [scrapy.utils.log] INFO: Versions:\n{'lxml': '5.4.0',\n 'libxml2': '2.13.8',\n 'cssselect': '1.3.0',\n 'parsel': '1.10.0',\n 'w3lib': '2.0.0',\n 'Twisted': '25.5.0',\n 'Python': '3.13.3 (main, Apr  9 2025, 07:44:25) [GCC 14.2.1 20250207]',\n 'pyOpenSSL': '25.1.0 (OpenSSL 3.5.0 8 Apr 2025)',\n 'cryptography': '45.0.4',\n 'Platform': 'Linux-6.14.6-2-MANJARO-x86_64-with-glibc2.41'}\n2025-06-23 19:58:26 [scrapy.addons] INFO: Enabled addons:\n[]\n2025-06-23 19:58:26 [asyncio] DEBUG: Using selector: EpollSelector\n2025-06-23 19:58:26 [scrapy.utils.log] DEBUG: Using reactor: twisted.internet.asyncioreactor.AsyncioSelectorReactor\n2025-06-23 19:58:26 [scrapy.utils.log] DEBUG: Using asyncio event loop: asyncio.unix_events._UnixSelectorEventLoop\n2025-06-23 19:58:26 [scrapy.extensions.telnet] INFO: Telnet Password: 8b97e889124eb4e5\n2025-06-23 19:58:26 [scrapy.middleware] INFO: Enabled extensions:\n['scrapy.extensions.corestats.CoreStats',\n 'scrapy.extensions.telnet.TelnetConsole',\n 'scrapy.extensions.memusage.MemoryUsage',\n 'scrapy.extensions.logstats.LogStats',\n 'scrapy.extensions.throttle.AutoThrottle']\n2025-06-23 19:58:26 [scrapy.crawler] INFO: Overridden settings:\n{'AUTOTHROTTLE_ENABLED': True,\n 'AUTOTHROTTLE_START_DELAY': 10,\n 'AUTOTHROTTLE_TARGET_CONCURRENCY': 0.5,\n 'BOT_NAME': 'itemspider',\n 'CONCURRENT_REQUESTS': 1,\n 'DOWNLOAD_DELAY': 10,\n 'EDITOR': '/usr/bin/nano',\n 'FEED_EXPORT_ENCODING': 'utf-8',\n 'HTTPCACHE_IGNORE_HTTP_CODES': [429],\n 'LOG_FILE': '/home/stefan/SteamScrapers/CS2Scraper/logs/itemspider/steamspider/2025-06-23T19_58_14.log',\n 'NEWSPIDER_MODULE': 'itemspider.spiders',\n 'SPIDER_MODULES': ['itemspider.spiders']}\n2025-06-23 19:58:26 [scrapy.middleware] INFO: Enabled downloader middlewares:\n['scrapy.downloadermiddlewares.offsite.OffsiteMiddleware',\n 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',\n 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',\n 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',\n 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',\n 'itemspider.middlewares.ItemspiderDownloaderMiddleware',\n 'scrapy.downloadermiddlewares.retry.RetryMiddleware',\n 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',\n 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',\n 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',\n 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',\n 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',\n 'scrapy.downloadermiddlewares.stats.DownloaderStats']\n2025-06-23 19:58:26 [scrapy.middleware] INFO: Enabled spider middlewares:\n['scrapy.spidermiddlewares.start.StartSpiderMiddleware',\n 'scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',\n 'itemspider.middlewares.ItemspiderSpiderMiddleware',\n 'scrapy.spidermiddlewares.referer.RefererMiddleware',\n 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',\n 'scrapy.spidermiddlewares.depth.DepthMiddleware']\n2025-06-23 19:58:26 [py.warnings] WARNING: /home/stefan/SteamScrapers/CS2Scraper/.venv/lib/python3.13/site-packages/scrapy/core/spidermw.py:98: ScrapyDeprecationWarning: The following enabled spider middlewares, directly or through their parent classes, define the deprecated process_start_requests() method: itemspider.middlewares.ItemspiderSpiderMiddleware. process_start_requests() has been deprecated in favor of a new method, process_start(), to support asynchronous code execution. process_start_requests() will stop being called in a future version of Scrapy. If you use Scrapy 2.13 or higher only, replace process_start_requests() with process_start(); note that process_start() is a coroutine (async def). If you need to maintain compatibility with lower Scrapy versions, when defining process_start_requests() in a spider middleware class, define process_start() as well. See the release notes of Scrapy 2.13 for details: https://docs.scrapy.org/en/2.13/news.html\n  warn(\n\n2025-06-23 19:58:26 [scrapy.core.spidermw] WARNING: Middleware itemspider.middlewares.ItemspiderSpiderMiddleware doesn't support asynchronous spider output, this is deprecated and will stop working in a future version of Scrapy. The middleware should be updated to support it. Please see https://docs.scrapy.org/en/latest/topics/coroutines.html#for-middleware-users for more information.\n2025-06-23 19:58:26 [scrapy.middleware] INFO: Enabled item pipelines:\n['itemspider.pipelines.ItemspiderPipeline']\n2025-06-23 19:58:26 [scrapy.core.engine] INFO: Spider opened\n2025-06-23 19:58:26 [py.warnings] WARNING: /home/stefan/SteamScrapers/CS2Scraper/.venv/lib/python3.13/site-packages/scrapy/core/spidermw.py:433: ScrapyDeprecationWarning: itemspider.spiders.steamspider.SteamspiderSpider defines the deprecated start_requests() method. start_requests() has been deprecated in favor of a new method, start(), to support asynchronous code execution. start_requests() will stop being called in a future version of Scrapy. If you use Scrapy 2.13 or higher only, replace start_requests() with start(); note that start() is a coroutine (async def). If you need to maintain compatibility with lower Scrapy versions, when overriding start_requests() in a spider class, override start() as well; you can use super() to reuse the inherited start() implementation without copy-pasting. See the release notes of Scrapy 2.13 for details: https://docs.scrapy.org/en/2.13/news.html\n  warn(\n\n2025-06-23 19:58:26 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)\n2025-06-23 19:58:26 [steamspider] INFO: Spider opened: steamspider\n2025-06-23 19:58:26 [steamspider] INFO: Spider opened: steamspider\n2025-06-23 19:58:26 [scrapy.extensions.telnet] INFO: Telnet console listening on 127.0.0.1:6023\n2025-06-23 19:58:30 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://steamcommunity.com/market/search/render/?query=&start=4000&count=100&search_descriptions=0&sort_column=price&sort_dir=desc&appid=730> (referer: None)\n2025-06-23 19:58:38 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://steamcommunity.com/market/search/render/?query=&start=5000&count=100&search_descriptions=0&sort_column=price&sort_dir=desc&appid=730> (referer: https://steamcommunity.com/market/search/render/?query=&start=4000&count=100&search_descriptions=0&sort_column=price&sort_dir=desc&appid=730)\n2025-06-23 19:58:38 [scrapy.dupefilters] DEBUG: Filtered duplicate request: <GET https://steamcommunity.com/market/search/render/?query=&start=5000&count=100&search_descriptions=0&sort_column=price&sort_dir=desc&appid=730> - no more duplicates will be shown (see DUPEFILTER_DEBUG to show all duplicates)\n2025-06-23 19:58:55 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://steamcommunity.com/market/search/render/?query=&start=6900&count=100&search_descriptions=0&sort_column=price&sort_dir=desc&appid=730> (referer: https://steamcommunity.com/market/search/render/?query=&start=4000&count=100&search_descriptions=0&sort_column=price&sort_dir=desc&appid=730)\n2025-06-23 19:59:05 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://steamcommunity.com/market/listings/730/Dust%20II%20Pin> (referer: https://steamcommunity.com/market/search/render/?query=&start=5000&count=100&search_descriptions=0&sort_column=price&sort_dir=desc&appid=730)\n2025-06-23 19:59:05 [scrapy.core.scraper] DEBUG: Scraped from <200 https://steamcommunity.com/market/listings/730/Dust%20II%20Pin>\n{'buying_price': 48.64,\n 'profit': -1.12,\n 'selling_price': 47.39,\n 'url': 'https://steamcommunity.com/market/listings/730/Dust%20II%20Pin'}\n2025-06-23 19:59:19 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://steamcommunity.com/market/listings/730/AK-47%20%7C%20Head%20Shot%20%28Minimal%20Wear%29> (referer: https://steamcommunity.com/market/search/render/?query=&start=6900&count=100&search_descriptions=0&sort_column=price&sort_dir=desc&appid=730)\n2025-06-23 19:59:19 [scrapy.core.scraper] DEBUG: Scraped from <200 https://steamcommunity.com/market/listings/730/AK-47%20%7C%20Head%20Shot%20%28Minimal%20Wear%29>\n{'buying_price': 19.5,\n 'profit': -0.05,\n 'selling_price': 19.444,\n 'url': 'https://steamcommunity.com/market/listings/730/AK-47%20%7C%20Head%20Shot%20%28Minimal%20Wear%29'}\n2025-06-23 19:59:26 [scrapy.extensions.logstats] INFO: Crawled 5 pages (at 5 pages/min), scraped 2 items (at 2 items/min)\n2025-06-23 19:59:31 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://steamcommunity.com/market/listings/730/Sticker%20%7C%20GuardiaN%20%28Gold%29%20%7C%20Berlin%202019> (referer: https://steamcommunity.com/market/search/render/?query=&start=6900&count=100&search_descriptions=0&sort_column=price&sort_dir=desc&appid=730)\n2025-06-23 19:59:31 [scrapy.core.scraper] DEBUG: Scraped from <200 https://steamcommunity.com/market/listings/730/Sticker%20%7C%20GuardiaN%20%28Gold%29%20%7C%20Berlin%202019>\n{'buying_price': 19.5,\n 'profit': 0.99,\n 'selling_price': 20.597,\n 'url': 'https://steamcommunity.com/market/listings/730/Sticker%20%7C%20GuardiaN%20%28Gold%29%20%7C%20Berlin%202019'}\n2025-06-23 19:59:45 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://steamcommunity.com/market/listings/730/Sticker%20%7C%20Starry%20%28Gold%29%20%7C%20Copenhagen%202024> (referer: https://steamcommunity.com/market/search/render/?query=&start=6900&count=100&search_descriptions=0&sort_column=price&sort_dir=desc&appid=730)\n2025-06-23 19:59:45 [scrapy.core.scraper] DEBUG: Scraped from <200 https://steamcommunity.com/market/listings/730/Sticker%20%7C%20Starry%20%28Gold%29%20%7C%20Copenhagen%202024>\n{'buying_price': 19.5,\n 'profit': 0.56,\n 'selling_price': 20.12,\n 'url': 'https://steamcommunity.com/market/listings/730/Sticker%20%7C%20Starry%20%28Gold%29%20%7C%20Copenhagen%202024'}\n2025-06-23 19:59:54 [scrapy.crawler] INFO: Received SIGINT, shutting down gracefully. Send again to force \n2025-06-23 19:59:54 [scrapy.core.engine] INFO: Closing spider (shutdown)\n2025-06-23 19:59:55 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://steamcommunity.com/market/listings/730/Sticker%20%7C%20WorldEdit%20%28Foil%29%20%7C%20Cologne%202015> (referer: https://steamcommunity.com/market/search/render/?query=&start=6900&count=100&search_descriptions=0&sort_column=price&sort_dir=desc&appid=730)\n2025-06-23 19:59:55 [scrapy.core.scraper] DEBUG: Scraped from <200 https://steamcommunity.com/market/listings/730/Sticker%20%7C%20WorldEdit%20%28Foil%29%20%7C%20Cologne%202015>\n{'buying_price': 19.5,\n 'profit': -3.25,\n 'selling_price': 15.884,\n 'url': 'https://steamcommunity.com/market/listings/730/Sticker%20%7C%20WorldEdit%20%28Foil%29%20%7C%20Cologne%202015'}\n2025-06-23 19:59:55 [scrapy.statscollectors] INFO: Dumping Scrapy stats:\n{'downloader/request_bytes': 4216,\n 'downloader/request_count': 8,\n 'downloader/request_method_count/GET': 8,\n 'downloader/response_bytes': 134271,\n 'downloader/response_count': 8,\n 'downloader/response_status_count/200': 8,\n 'dupefilter/filtered': 40,\n 'elapsed_time_seconds': 89.228958,\n 'finish_reason': 'shutdown',\n 'finish_time': datetime.datetime(2025, 6, 23, 17, 59, 55, 993039, tzinfo=datetime.timezone.utc),\n 'httpcompression/response_bytes': 667643,\n 'httpcompression/response_count': 8,\n 'item_scraped_count': 5,\n 'items_per_minute': 3.3707865168539324,\n 'log_count/DEBUG': 17,\n 'log_count/INFO': 14,\n 'log_count/WARNING': 3,\n 'memusage/max': 99995648,\n 'memusage/startup': 86732800,\n 'request_depth_max': 2,\n 'response_received_count': 8,\n 'responses_per_minute': 5.393258426966292,\n 'scheduler/dequeued': 8,\n 'scheduler/dequeued/memory': 8,\n 'scheduler/enqueued': 41,\n 'scheduler/enqueued/memory': 41,\n 'start_time': datetime.datetime(2025, 6, 23, 17, 58, 26, 764081, tzinfo=datetime.timezone.utc)}\n2025-06-23 19:59:55 [scrapy.core.engine] INFO: Spider closed (shutdown)\n",
    "first_log_time": "2025-06-23 19:58:26",
    "latest_log_time": "2025-06-23 19:59:55",
    "runtime": "0:01:29",
    "first_log_timestamp": 1750701506,
    "latest_log_timestamp": 1750701595,
    "datas": [
        [
            "2025-06-23 19:58:26",
            0,
            0,
            0,
            0
        ],
        [
            "2025-06-23 19:59:26",
            5,
            5,
            2,
            2
        ]
    ],
    "pages": 8,
    "items": 5,
    "latest_matches": {
        "scrapy_version": "2.13.2",
        "telnet_console": "127.0.0.1:6023",
        "telnet_username": "",
        "telnet_password": "8b97e889124eb4e5",
        "resuming_crawl": "",
        "latest_offsite": "",
        "latest_duplicate": "2025-06-23 19:58:38 [scrapy.dupefilters] DEBUG: Filtered duplicate request: <GET https://steamcommunity.com/market/search/render/?query=&start=5000&count=100&search_descriptions=0&sort_column=price&sort_dir=desc&appid=730> - no more duplicates will be shown (see DUPEFILTER_DEBUG to show all duplicates)",
        "latest_crawl": "2025-06-23 19:59:55 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://steamcommunity.com/market/listings/730/Sticker%20%7C%20WorldEdit%20%28Foil%29%20%7C%20Cologne%202015> (referer: https://steamcommunity.com/market/search/render/?query=&start=6900&count=100&search_descriptions=0&sort_column=price&sort_dir=desc&appid=730)",
        "latest_stat": "2025-06-23 19:59:26 [scrapy.extensions.logstats] INFO: Crawled 5 pages (at 5 pages/min), scraped 2 items (at 2 items/min)",
        "latest_scrape": "2025-06-23 19:59:55 [scrapy.core.scraper] DEBUG: Scraped from <200 https://steamcommunity.com/market/listings/730/Sticker%20%7C%20WorldEdit%20%28Foil%29%20%7C%20Cologne%202015>",
        "latest_item": "{'buying_price': 19.5,\n 'profit': -3.25,\n 'selling_price': 15.884,\n 'url': 'https://steamcommunity.com/market/listings/730/Sticker%20%7C%20WorldEdit%20%28Foil%29%20%7C%20Cologne%202015'}"
    },
    "latest_crawl_timestamp": 1750701595,
    "latest_scrape_timestamp": 1750701595,
    "log_categories": {
        "critical_logs": {
            "count": 0,
            "details": []
        },
        "error_logs": {
            "count": 0,
            "details": []
        },
        "warning_logs": {
            "count": 3,
            "details": [
                "2025-06-23 19:58:26 [py.warnings] WARNING: /home/stefan/SteamScrapers/CS2Scraper/.venv/lib/python3.13/site-packages/scrapy/core/spidermw.py:98: ScrapyDeprecationWarning: The following enabled spider middlewares, directly or through their parent classes, define the deprecated process_start_requests() method: itemspider.middlewares.ItemspiderSpiderMiddleware. process_start_requests() has been deprecated in favor of a new method, process_start(), to support asynchronous code execution. process_start_requests() will stop being called in a future version of Scrapy. If you use Scrapy 2.13 or higher only, replace process_start_requests() with process_start(); note that process_start() is a coroutine (async def). If you need to maintain compatibility with lower Scrapy versions, when defining process_start_requests() in a spider middleware class, define process_start() as well. See the release notes of Scrapy 2.13 for details: https://docs.scrapy.org/en/2.13/news.html\n  warn(\n",
                "2025-06-23 19:58:26 [scrapy.core.spidermw] WARNING: Middleware itemspider.middlewares.ItemspiderSpiderMiddleware doesn't support asynchronous spider output, this is deprecated and will stop working in a future version of Scrapy. The middleware should be updated to support it. Please see https://docs.scrapy.org/en/latest/topics/coroutines.html#for-middleware-users for more information.",
                "2025-06-23 19:58:26 [py.warnings] WARNING: /home/stefan/SteamScrapers/CS2Scraper/.venv/lib/python3.13/site-packages/scrapy/core/spidermw.py:433: ScrapyDeprecationWarning: itemspider.spiders.steamspider.SteamspiderSpider defines the deprecated start_requests() method. start_requests() has been deprecated in favor of a new method, start(), to support asynchronous code execution. start_requests() will stop being called in a future version of Scrapy. If you use Scrapy 2.13 or higher only, replace start_requests() with start(); note that start() is a coroutine (async def). If you need to maintain compatibility with lower Scrapy versions, when overriding start_requests() in a spider class, override start() as well; you can use super() to reuse the inherited start() implementation without copy-pasting. See the release notes of Scrapy 2.13 for details: https://docs.scrapy.org/en/2.13/news.html\n  warn(\n"
            ]
        },
        "redirect_logs": {
            "count": 0,
            "details": []
        },
        "retry_logs": {
            "count": 0,
            "details": []
        },
        "ignore_logs": {
            "count": 0,
            "details": []
        }
    },
    "shutdown_reason": "Received SIGINT",
    "finish_reason": "shutdown",
    "crawler_stats": {
        "source": "log",
        "last_update_time": "2025-06-23 19:59:55",
        "last_update_timestamp": 1750701595,
        "downloader/request_bytes": 4216,
        "downloader/request_count": 8,
        "downloader/request_method_count/GET": 8,
        "downloader/response_bytes": 134271,
        "downloader/response_count": 8,
        "downloader/response_status_count/200": 8,
        "dupefilter/filtered": 40,
        "elapsed_time_seconds": 89.228958,
        "finish_reason": "shutdown",
        "finish_time": "datetime.datetime(2025, 6, 23, 17, 59, 55, 993039, tzinfo=datetime.timezone.utc)",
        "httpcompression/response_bytes": 667643,
        "httpcompression/response_count": 8,
        "item_scraped_count": 5,
        "items_per_minute": 3.3707865168539324,
        "log_count/DEBUG": 17,
        "log_count/INFO": 14,
        "log_count/WARNING": 3,
        "memusage/max": 99995648,
        "memusage/startup": 86732800,
        "request_depth_max": 2,
        "response_received_count": 8,
        "responses_per_minute": 5.393258426966292,
        "scheduler/dequeued": 8,
        "scheduler/dequeued/memory": 8,
        "scheduler/enqueued": 41,
        "scheduler/enqueued/memory": 41,
        "start_time": "datetime.datetime(2025, 6, 23, 17, 58, 26, 764081, tzinfo=datetime.timezone.utc)"
    },
    "last_update_time": "2025-07-08 19:58:50",
    "last_update_timestamp": 1751997530,
    "logparser_version": "0.8.4",
    "crawler_engine": {}
}